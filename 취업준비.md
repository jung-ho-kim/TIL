# 취업준비



aws 자격증, 하둡, 스파크,Django

정처기, 빅데이터분석기사



[자격요건] 

-  Airflow, Luigi 등을 이용한 배치 파이프라인(ETL)처리 경력 3년 이상이신 분 

-  데이터 처리를 위한 SQL 및 프로그램 능력이 있으신 분 

- Python, Java, Scala 이용한 개발 경험이 있으신 분 

-  데이터 가공 및 분산처리 플랫폼에 대한 이해가 있으신 분 

  [우대사항]  

  - Data Warehouse 구축 및 Business intelligence 경험이 있으신 분 
  -  실시간 데이터 처리 경험(druid, spark streaming 등) 
  -  다양한 로그 데이터 운영 경험 
  -  Hadoop, Spark, Kafka 등의 데이터플랫폼 관련 경험 
  -  확장성 및 신뢰성 중심의 아키텍쳐를 설계할 수 있는 분



###### 자격요건

• 자료구조, 알고리즘, OS, 데이터베이스 등 기초 전산 지식이 있는 분
• SQL, Airflow, Hadoop, Kafka, Flink 등을 사용한 대용량 데이터 처리에 능숙한 분
• Java, Kotlin, Python 중 하나 이상의 언어에 익숙한 분
• 총 경력이 3년 이상인 분

###### 우대사항

• Hadoop EcoSystem 기반의 다양한 솔루션 활용 경험이 있는 분
• 은행 DW 업무 도메인을 잘 이해하고 있고 마트 개발 경험이 있는 분
• MySql, Oracle 의 CDC 경험이 있는 분
• 실시간 데이터 스트리밍 처리에 경험이 있고 익숙한 분